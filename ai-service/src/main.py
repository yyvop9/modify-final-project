import logging
import json
import re
import base64
from fastapi import FastAPI, HTTPException, APIRouter, UploadFile, File
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager

from src.core.model_engine import model_engine
from src.core.prompts import VISION_ANALYSIS_PROMPT
from src.services.rag_orchestrator import rag_orchestrator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ai-service")

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ AI Service Starting...")
    try:
        model_engine.initialize()
    except Exception as e:
        logger.error(f"âš ï¸ Model init warning: {e}")
    yield
    logger.info("ğŸ’¤ AI Service Shutting down...")

app = FastAPI(title="Modify AI Service", version="1.0.0", lifespan=lifespan)
api_router = APIRouter(prefix="/api/v1")

# --- DTO ---
class EmbedRequest(BaseModel):
    text: str

class AnalyzeRequest(BaseModel):
    image_b64: str
    query: str   

class EmbedResponse(BaseModel):
    vector: List[float]

class ImageAnalysisResponse(BaseModel):
    name: str
    category: str
    gender: str
    description: str
    price: int
    vector: List[float]           # BERT ë²¡í„° (768ì°¨ì›)
    vector_clip: List[float]      # CLIP ë²¡í„° (512ì°¨ì›) - ì‹ ê·œ ì¶”ê°€

class PathRequest(BaseModel):
    query: str

class InternalSearchRequest(BaseModel):
    query: str
    image_b64: Optional[str] = None

# CLIP ë²¡í„° ìƒì„± ìš”ì²­
class ClipVectorRequest(BaseModel):
    image_b64: str

class ClipVectorResponse(BaseModel):
    vector: List[float]
    dimension: int

# ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ìš”ì²­
class ImageSearchRequest(BaseModel):
    image_b64: str
    limit: int = 12

# --- Helper Methods (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ---

def _fix_encoding(text: str) -> str:
    """
    [í•µì‹¬] ê¹¨ì§„ í•œê¸€(Mojibake) ë° ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ì™„ë²½ ë³µêµ¬
    """
    if not text:
        return ""

    # 1. Mojibake ë³µêµ¬ ì‹œë„ (Latin-1 -> UTF-8)
    try:
        fixed = text.encode('latin1').decode('utf-8')
        return fixed
    except Exception:
        pass

    # 2. ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë³µêµ¬ ì‹œë„
    try:
        return text.encode('utf-8').decode('unicode_escape')
    except Exception:
        pass
        
    return text

def _extract_from_text(text: str, key_patterns: List[str], default: str = "") -> str:
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ ì¶”ì¶œ + ì¸ì½”ë”© ìë™ ë³´ì •"""
    for pattern in key_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            clean_val = match.group(1).strip().strip('",').strip()
            return _fix_encoding(clean_val)
    return default

# --- Endpoints (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€) ---

@api_router.post("/embed-text", response_model=EmbedResponse)
async def embed_text(request: EmbedRequest):
    try:
        vector = model_engine.generate_embedding(request.text)
        return {"vector": vector}
    except:
        return {"vector": [0.0] * 768} 

@api_router.post("/analyze-image", response_model=ImageAnalysisResponse)
async def analyze_image(file: UploadFile = File(...)):
    """
    ì´ë¯¸ì§€ ë¶„ì„ ë° ìƒí’ˆ ì •ë³´ ìƒì„±
    - BERT ë²¡í„° (768ì°¨ì›): í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ìš©
    - CLIP ë²¡í„° (512ì°¨ì›): ì´ë¯¸ì§€ ê¸°ë°˜ ì‹œê°ì  ìœ ì‚¬ë„ ê²€ìƒ‰ìš©
    """
    filename = file.filename
    try:
        contents = await file.read()
        image_b64 = base64.b64encode(contents).decode("utf-8")
        
        prompt = VISION_ANALYSIS_PROMPT
        
        logger.info(f"ğŸ‘ï¸ Analyzing image: {filename}...")
        generated_text = model_engine.generate_with_image(prompt, image_b64)
        
        # [Critical] 1ì°¨ ì¸ì½”ë”© ë³´ì •
        generated_text = _fix_encoding(generated_text)
        logger.info(f"ğŸ¤– Raw AI Response: {generated_text}")

        if "cannot assist" in generated_text or "I cannot" in generated_text:
            raise ValueError("AI Safety Filter Triggered")

        product_data = {}
        parsing_success = False

        # JSON íŒŒì‹± ì‹œë„
        try:
            json_match = re.search(r"\{[\s\S]*\}", generated_text)
            if json_match:
                clean_json = json_match.group()
                clean_json = re.sub(r"```json|```", "", clean_json)
                product_data = json.loads(clean_json)
                parsing_success = True
            else:
                product_data = json.loads(generated_text)
                parsing_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ JSON Parsing failed: {e}. Attempting Fallback Regex...")

        # Fallback Parser
        if not parsing_success:
            logger.info("ğŸ”§ Running Fallback Parser...")
            product_data["name"] = _extract_from_text(generated_text, [r'"?name"?\s*:\s*"([^"]+)"', r'"?ì´ë¦„"?\s*:\s*"([^"]+)"', r'Name:\s*(.+)'])
            product_data["category"] = _extract_from_text(generated_text, [r'"?category"?\s*:\s*"([^"]+)"', r'"?ì¹´í…Œê³ ë¦¬"?\s*:\s*"([^"]+)"', r'Category:\s*(.+)'], "Uncategorized")
            product_data["gender"] = _extract_from_text(generated_text, [r'"?gender"?\s*:\s*"([^"]+)"', r'"?ì„±ë³„"?\s*:\s*"([^"]+)"', r'Gender:\s*(.+)'], "Unisex")
            product_data["description"] = _extract_from_text(generated_text, [r'"?description"?\s*:\s*"([^"]+)"', r'"?ì„¤ëª…"?\s*:\s*"([^"]+)"', r'Description:\s*(.+)'], "AI ìƒì„¸ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤.")
            price_str = _extract_from_text(generated_text, [r'"?price"?\s*:\s*([\d,]+)', r'"?ê°€ê²©"?\s*:\s*([\d,]+)', r'Price:\s*([\d,]+)'], "0")
            try:
                product_data["price"] = int(re.sub(r"[^0-9]", "", price_str))
            except:
                product_data["price"] = 0

        # ë°ì´í„° ì •ê·œí™” ë° ë²¡í„° ìƒì„±
        final_name = _fix_encoding(product_data.get("name"))
        if not final_name or "ìƒí’ˆëª…" in final_name or "JSON" in final_name:
             final_name = f"AI ì¶”ì²œ ìƒí’ˆ ({filename.split('.')[0]})"
        
        final_desc = _fix_encoding(product_data.get("description"))
        if not final_desc or len(final_desc) < 5:
            final_desc = "AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì²œí•˜ëŠ” ìƒí’ˆì…ë‹ˆë‹¤."

        final_cat = _fix_encoding(product_data.get("category", "Uncategorized"))
        
        raw_gender = str(product_data.get("gender", "Unisex"))
        if any(x in raw_gender.lower() for x in ['wo', 'female', 'girl', 'lady', 'ì—¬ì„±', 'ì—¬ì']):
            final_gender = 'Female'
        elif any(x in raw_gender.lower() for x in ['man', 'male', 'boy', 'ë‚¨ì„±', 'ë‚¨ì']):
            final_gender = 'Male'
        else:
            final_gender = 'Unisex'

        try:
            raw_price = str(product_data.get("price", 0))
            price = int(re.sub(r"[^0-9]", "", raw_price))
        except:
            price = 0

        # ============================================================
        # [BERT ë²¡í„°] í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ë² ë”© (768ì°¨ì›)
        # ============================================================
        meta_text = f"[{final_gender}] {final_name} {final_cat} {final_desc}"
        vector = model_engine.generate_embedding(meta_text)

        # ============================================================
        # [CLIP ë²¡í„°] ì´ë¯¸ì§€ ê¸°ë°˜ ì‹œê°ì  ì„ë² ë”© (512ì°¨ì›) - ì‹ ê·œ ì¶”ê°€!
        # ============================================================
        vector_clip = []
        try:
            clip_result = model_engine.generate_image_embedding(image_b64)
            vector_clip = clip_result.get("clip", [])
            if vector_clip:
                logger.info(f"ğŸ–¼ï¸ CLIP vector generated: {len(vector_clip)} dimensions")
            else:
                logger.warning("âš ï¸ CLIP vector empty, using zeros")
                vector_clip = [0.0] * 512
        except Exception as e:
            logger.error(f"âŒ CLIP vector generation failed: {e}")
            vector_clip = [0.0] * 512

        logger.info(f"âœ… Analysis Success: {final_name} ({final_gender}) - {price}ì›")
        logger.info(f"   ğŸ“Š BERT: {len(vector)}dim, CLIP: {len(vector_clip)}dim")

        return {
            "name": final_name,
            "category": final_cat,
            "gender": final_gender,
            "description": final_desc,
            "price": price,
            "vector": vector,           # BERT 768ì°¨ì›
            "vector_clip": vector_clip  # CLIP 512ì°¨ì›
        }

    except Exception as e:
        logger.error(f"âŒ Analysis Critical Error: {e}")
        return {
            "name": f"ë“±ë¡ëœ ìƒí’ˆ ({filename})",
            "category": "Etc",
            "gender": "Unisex",
            "description": "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨.",
            "price": 0,
            "vector": [0.0] * 768,
            "vector_clip": [0.0] * 512
        }

@api_router.post("/llm-generate-response")
async def llm_generate(body: Dict[str, str]):
    prompt = body.get("prompt", "")
    try:
        korean_prompt = f"ì§ˆë¬¸: {prompt}\në‹µë³€ (í•œêµ­ì–´):"
        answer = model_engine.generate_text(korean_prompt)
        return {"answer": answer}
    except:
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
@api_router.post("/analyze-image-detail")
async def analyze_image_detail(req: AnalyzeRequest):
    """íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ìš”ì²­ (RAGìš© - base64 ì´ë¯¸ì§€)"""
    result = await rag_orchestrator.analyze_specific_image(req.image_b64, req.query)
    return {"analysis": result}    


# -------------------------------------------------------------
# CLIP ì´ë¯¸ì§€ ë²¡í„° ìƒì„± ì—”ë“œí¬ì¸íŠ¸
# -------------------------------------------------------------

@api_router.post("/generate-clip-vector", response_model=ClipVectorResponse)
async def generate_clip_vector(request: ClipVectorRequest):
    """
    ì´ë¯¸ì§€ì—ì„œ CLIP ë²¡í„°(512ì°¨ì›) ìƒì„±
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ ìƒí’ˆ ì¬ê²€ìƒ‰ì— ì‚¬ìš©
    - ìƒí’ˆ ë“±ë¡ ì‹œ CLIP ë²¡í„° ì €ì¥ì— ì‚¬ìš©
    """
    try:
        image_b64 = request.image_b64
        
        # data:image/... í˜•ì‹ì´ë©´ base64 ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # CLIP Vision ëª¨ë¸ë¡œ ë²¡í„° ìƒì„± (YOLO ì ìš©)
        result = model_engine.generate_image_embedding(image_b64, use_yolo=True)
        clip_vector = result.get("clip", [])
        
        if not clip_vector or len(clip_vector) == 0:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"âœ… CLIP vector generated: {len(clip_vector)} dimensions")
        
        return {
            "vector": clip_vector,
            "dimension": len(clip_vector)
        }
        
    except Exception as e:
        logger.error(f"âŒ CLIP vector generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# âœ… NEW: íŒ¨ì…˜ íŠ¹í™” CLIP ë²¡í„° ìƒì„± (YOLO + ìƒì˜/í•˜ì˜ ë¶„ë¦¬)
class FashionClipRequest(BaseModel):
    image_b64: str
    target: str = "full"  # "full", "upper", "lower"


@api_router.post("/generate-fashion-clip-vector")
async def generate_fashion_clip_vector(request: FashionClipRequest):
    """
    âœ… íŒ¨ì…˜ íŠ¹í™” CLIP ë²¡í„° ìƒì„±
    - YOLOë¡œ ì‚¬ëŒ/ì˜· ì˜ì—­ ê°ì§€ í›„ í¬ë¡­
    - target: "full"(ì „ì‹ ), "upper"(ìƒì˜), "lower"(í•˜ì˜)
    """
    try:
        image_b64 = request.image_b64
        target = request.target
        
        # data:image/... í˜•ì‹ì´ë©´ base64 ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # PIL Imageë¡œ ë³€í™˜
        import io
        from PIL import Image
        pil_image = Image.open(io.BytesIO(base64.b64decode(image_b64)))
        
        # YOLOë¡œ ì˜ì—­ í¬ë¡­ í›„ CLIP ë²¡í„° ìƒì„±
        try:
            from src.core.yolo_detector import yolo_detector
            
            # YOLO ì´ˆê¸°í™”
            if not yolo_detector.initialized:
                yolo_detector.initialize()
            
            # ì§€ì •ëœ ì˜ì—­ í¬ë¡­
            cropped = yolo_detector.crop_fashion_regions(pil_image, target=target)
            
            if cropped is not None:
                logger.info(f"âœ‚ï¸ YOLO cropped '{target}' region: {cropped.size}")
                pil_image = cropped
            else:
                logger.warning(f"âš ï¸ YOLO crop failed for '{target}', using original")
                
        except ImportError as e:
            logger.warning(f"âš ï¸ YOLO not available: {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ YOLO failed: {e}")
        
        # CLIP ë²¡í„° ìƒì„± (YOLO ì¤‘ë³µ ì ìš© ë°©ì§€)
        result = model_engine.generate_image_embedding(pil_image, use_yolo=False)
        clip_vector = result.get("clip", [])
        
        if not clip_vector or len(clip_vector) == 0:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"âœ… Fashion CLIP vector generated ({target}): {len(clip_vector)} dimensions")
        
        return {
            "vector": clip_vector,
            "dimension": len(clip_vector),
            "target": target
        }
        
    except Exception as e:
        logger.error(f"âŒ Fashion CLIP vector generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.post("/search-by-image")
async def search_by_image(request: ImageSearchRequest):
    """
    ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ì§€ â†’ CLIP ë²¡í„° â†’ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰
    """
    try:
        image_b64 = request.image_b64
        
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # CLIP ë²¡í„° ìƒì„±
        result = model_engine.generate_image_embedding(image_b64)
        clip_vector = result.get("clip", [])
        
        if not clip_vector:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"ğŸ–¼ï¸ Image search: CLIP vector generated ({len(clip_vector)} dims)")
        
        return {
            "vectors": {
                "clip": clip_vector,
                "bert": None
            },
            "search_type": "image_similarity"
        }
        
    except Exception as e:
        logger.error(f"âŒ Image search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# -------------------------------------------------------------
#  RAG Orchestrator ì—°ê²° (ê²€ìƒ‰ ë¡œì§ ê³ ë„í™”)
# -------------------------------------------------------------

@api_router.post("/determine-path")
async def determine_path(request: PathRequest):
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê²½ë¡œ(INTERNAL vs EXTERNAL)ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ¤” Determining path for query: {request.query}")
    try:
        decision = await rag_orchestrator.determine_search_path(request.query)
        logger.info(f"ğŸ‘‰ Decision: {decision}")
        return {"path": decision}
    except Exception as e:
        logger.error(f"Determine path error: {e}")
        return {"path": "INTERNAL"}

@api_router.post("/process-internal")
async def process_internal(request: InternalSearchRequest):
    """
    ë‚´ë¶€ ê²€ìƒ‰ ë¡œì§ ì‹¤í–‰
    """
    logger.info(f"ğŸ¢ Processing Internal (Orchestrator): {request.query}")
    return await rag_orchestrator.process_internal_search(request.query)

@api_router.post("/process-external")
async def process_external(request: InternalSearchRequest):
    """
    ì™¸ë¶€(Google+RAG) ê²€ìƒ‰ ë¡œì§ ì‹¤í–‰
    """
    logger.info(f"ğŸŒ Processing External (Orchestrator): {request.query}")
    try:
        result = await rag_orchestrator.process_external_rag(request.query)
        return result
    except Exception as e:
        logger.error(f"External processing failed: {e}")
        return await rag_orchestrator.process_internal_search(request.query)

app.include_router(api_router)

@app.get("/")
def read_root():
    return {"message": "Modify AI Service is Running"}