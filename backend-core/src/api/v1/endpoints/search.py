"""
search.py - ìˆ˜ì •ëœ ë²„ì „ v2
ê²½ë¡œ: backend-core/src/api/v1/endpoints/search.py

ìˆ˜ì • ì‚¬í•­:
1. í…ìŠ¤íŠ¸ë§Œ ìžˆì–´ë„ determine-path í˜¸ì¶œ
2. EXTERNAL ê²½ë¡œì¼ ë•Œ CLIP ì´ë¯¸ì§€ ë²¡í„°ë¡œ ê²€ìƒ‰ (í•µì‹¬ ìˆ˜ì •!)
3. í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œ ì—°ì˜ˆì¸ ê²€ìƒ‰ ê³ ë ¤
"""

import logging
import base64
import asyncio
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession
import httpx
from pydantic import BaseModel, ValidationError 

from src.api import deps
from src.crud.crud_product import crud_product
from src.schemas.product import ProductResponse
from src.config.settings import settings

logger = logging.getLogger(__name__)
router = APIRouter()

# DTO
class ImageAnalysisRequest(BaseModel):
    image_b64: str
    query: str


def detect_gender_intent(query: str) -> Optional[str]:
    """ê²€ìƒ‰ì–´ì—ì„œ ì„±ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    q = query.lower()
    if any(x in q for x in ["ë‚¨ìž", "ë‚¨ì„±", "ë§¨", "men", "male", "boy"]):
        return "Male"
    elif any(x in q for x in ["ì—¬ìž", "ì—¬ì„±", "ìš°ë¨¼", "women", "female", "girl"]):
        return "Female"
    return None


def extract_core_keyword(query: str) -> str:
    """ê²€ìƒ‰ì–´ì—ì„œ í•µì‹¬ ìƒí’ˆ í‚¤ì›Œë“œ ì¶”ì¶œ (ì„±ë³„/ìˆ˜ì‹ì–´ ì œê±°)"""
    import re
    
    # ì œê±°í•  ë‹¨ì–´ë“¤
    remove_words = [
        "ë‚¨ìž", "ì—¬ìž", "ë‚¨ì„±", "ì—¬ì„±", "ë‚¨ì„±ìš©", "ì—¬ì„±ìš©",
        "ì¶”ì²œ", "í•´ì¤˜", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜",
        "ìŠ¤íƒ€ì¼", "íŒ¨ì…˜", "ì˜·", "ì˜ë¥˜", "ìš©"
    ]
    
    result = query
    for word in remove_words:
        result = result.replace(word, "")
    
    # ì¡°ì‚¬ ì œê±°
    result = re.sub(r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ë¡œ)$', '', result.strip())
    
    return result.strip() if result.strip() else query


def is_celebrity_search(query: str) -> bool:
    """ì—°ì˜ˆì¸/ì¸ë¬¼ ê²€ìƒ‰ì¸ì§€ íŒë‹¨"""
    import re
    
    # íŒ¨ì…˜ ê´€ë ¨ í‚¤ì›Œë“œì™€ í•¨ê»˜ ì‚¬ìš©ëœ ê²½ìš°
    fashion_keywords = ["íŒ¨ì…˜", "ìŠ¤íƒ€ì¼", "ì½”ë””", "ë£©", "ê³µí•­", "ì°©ìž¥", "ì˜ìƒ", "ì˜·"]
    
    # í•œê¸€ ì´ë¦„ íŒ¨í„´ (2-4ê¸€ìž)
    korean_name = re.search(r'[ê°€-íž£]{2,4}', query)
    
    if korean_name and any(k in query for k in fashion_keywords):
        return True
    
    return False


async def fetch_image_as_base64(url: str) -> Optional[str]:
    """ì™¸ë¶€ ì´ë¯¸ì§€ í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ"""
    if not url:
        return None
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Referer": "https://www.google.com/"
        }
        async with httpx.AsyncClient(timeout=5.0, verify=False) as client:
            response = await client.get(url, headers=headers)
            if response.status_code == 200:
                b64_data = base64.b64encode(response.content).decode('utf-8')
                content_type = response.headers.get("content-type", "image/jpeg")
                return f"data:{content_type};base64,{b64_data}"
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to proxy image ({url}): {e}")
    return None


# âœ… NEW: CLIP ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸
class ClipSearchRequest(BaseModel):
    image_b64: str
    limit: int = 12
    query: Optional[str] = None  # âœ… ì›ë³¸ ê²€ìƒ‰ì–´ (ì„±ë³„ ì¶”ì¶œìš©)
    target: str = "full"  # âœ… "full", "upper", "lower"


@router.post("/search-by-clip")
async def search_by_clip_image(
    request: ClipSearchRequest,
    db: AsyncSession = Depends(deps.get_db),
):
    """
    ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ì§€ â†’ CLIP ë²¡í„° â†’ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰
    - âœ… ì›ë³¸ ì¿¼ë¦¬ì—ì„œ ì„±ë³„ ì¶”ì¶œí•˜ì—¬ í•„í„°ë§
    - âœ… target: "full"(ì „ì²´), "upper"(ìƒì˜), "lower"(í•˜ì˜)
    """
    logger.info(f"ðŸ–¼ï¸ CLIP Image Search Request (limit: {request.limit}, query: {request.query}, target: {request.target})")
    
    # âœ… ì›ë³¸ ì¿¼ë¦¬ì—ì„œ ì„±ë³„ ì¶”ì¶œ
    target_gender = None
    if request.query:
        target_gender = detect_gender_intent(request.query)
        logger.info(f"ðŸ“Œ Detected gender from query: {target_gender}")
    
    # âœ… targetì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ í•„í„°
    category_filter = None
    if request.target == "upper":
        category_filter = ["Tops", "Outerwear", "Shirts", "Sweaters", "ìƒì˜", "ì•„ìš°í„°", "ì…”ì¸ ", "ë‹ˆíŠ¸"]
    elif request.target == "lower":
        category_filter = ["Bottoms", "Pants", "Skirts", "í•˜ì˜", "ë°”ì§€", "ì¹˜ë§ˆ"]
    
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    
    try:
        # 1. AI ì„œë¹„ìŠ¤ì—ì„œ CLIP ë²¡í„° ìƒì„± (YOLO + ì˜ì—­ ì§€ì •)
        async with httpx.AsyncClient(timeout=30.0) as client:
            clip_res = await client.post(
                f"{AI_SERVICE_API_URL}/generate-fashion-clip-vector",
                json={
                    "image_b64": request.image_b64,
                    "target": request.target  # âœ… ì˜ì—­ ì§€ì •
                }
            )
            
            if clip_res.status_code != 200:
                # Fallback: ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸
                logger.warning("âš ï¸ Fashion CLIP endpoint failed, falling back to standard CLIP")
                clip_res = await client.post(
                    f"{AI_SERVICE_API_URL}/generate-clip-vector",
                    json={"image_b64": request.image_b64}
                )
            
            if clip_res.status_code != 200:
                raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
            
            clip_data = clip_res.json()
            clip_vector = clip_data.get("vector", [])
            
            if not clip_vector or len(clip_vector) != 512:
                raise HTTPException(status_code=500, detail="ìœ íš¨í•˜ì§€ ì•Šì€ CLIP ë²¡í„°")
        
        logger.info(f"âœ… CLIP vector generated: {len(clip_vector)} dims (target: {request.target})")
        
        # 2. CLIP ë²¡í„°ë¡œ ìƒí’ˆ ê²€ìƒ‰ (âœ… ì„±ë³„ í•„í„° ì ìš©)
        results = await crud_product.search_by_clip_vector(
            db,
            clip_vector=clip_vector,
            limit=request.limit,
            filter_gender=target_gender  # âœ… ì„±ë³„ í•„í„° ì¶”ê°€!
        )
        
        logger.info(f"âœ… CLIP search found {len(results)} products (gender filter: {target_gender})")
        
        # 3. Response êµ¬ì„±
        product_responses = []
        for p in results:
            try:
                p_dict = {
                    "id": p.id,
                    "name": p.name or "Unnamed Product",
                    "description": p.description or "",
                    "price": float(p.price) if p.price else 0,
                    "stock_quantity": int(p.stock_quantity) if p.stock_quantity else 0,
                    "category": p.category or "Etc",
                    "image_url": p.image_url or "",
                    "gender": p.gender or "Unisex",
                    "is_active": p.is_active if p.is_active is not None else True,
                    "created_at": p.created_at,
                    "updated_at": p.updated_at,
                    "in_stock": (p.stock_quantity or 0) > 0
                }
                validated_product = ProductResponse.model_validate(p_dict)
                product_responses.append(validated_product)
            except ValidationError:
                continue
        
        return {
            "status": "SUCCESS",
            "search_type": "CLIP_IMAGE_SIMILARITY",
            "products": product_responses
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ CLIP search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-image")
async def analyze_image_proxy(request: ImageAnalysisRequest):
    """ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡ì‹œ (í›„ë³´ ì´ë¯¸ì§€ ìƒì„¸ ë¶„ì„)"""
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL.rstrip("/")
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            # âœ… /analyze-image-detail ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (JSON body ë²„ì „)
            target_url = f"{AI_SERVICE_API_URL}/analyze-image-detail"
            if "/api/v1" not in AI_SERVICE_API_URL:
                target_url = f"{AI_SERVICE_API_URL}/api/v1/analyze-image-detail"
            
            logger.info(f"ðŸ“¤ Calling AI Service: {target_url}")

            response = await client.post(
                target_url,
                json={"image_b64": request.image_b64, "query": request.query}
            )
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as e:
        logger.error(f"âŒ AI Service HTTP Error: {e.response.status_code} - {e.response.text}")
        raise HTTPException(status_code=502, detail=f"AI Service Error: {e.response.status_code}")
    except Exception as e:
        logger.error(f"âŒ Analysis Proxy Failed: {e}")
        raise HTTPException(status_code=500, detail=f"AI Service Error: {str(e)}")


@router.post("/ai-search", response_model=Dict[str, Any])
async def ai_search(
    query: str = Form(..., description="ì‚¬ìš©ìž ê²€ìƒ‰ ì¿¼ë¦¬"),
    image_file: Optional[UploadFile] = File(None),
    limit: int = Form(12),
    db: AsyncSession = Depends(deps.get_db),
) -> Any:
    """
    [Upgraded v2] ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    - í‚¤ì›Œë“œ ë§¤ì¹­ ìš°ì„  (ì¼ë°˜ ê²€ìƒ‰)
    - âœ… EXTERNAL ê²½ë¡œ: CLIP ì´ë¯¸ì§€ ë²¡í„°ë¡œ ì‹œê°ì  ìœ ì‚¬ë„ ê²€ìƒ‰
    - ì„±ë³„ í•„í„° ìžë™ ì ìš©
    """
    logger.info(f"ðŸ” AI Search Request: '{query}' (Image: {image_file is not None})")

    # 1. ì˜ë„ íŒŒì•…
    target_gender = detect_gender_intent(query)
    core_keyword = extract_core_keyword(query)
    is_celeb_search = is_celebrity_search(query)
    
    logger.info(f"ðŸ“Œ Gender: {target_gender}, Core Keyword: '{core_keyword}', Celebrity: {is_celeb_search}")

    # 2. ì´ë¯¸ì§€ ì²˜ë¦¬
    image_b64: Optional[str] = None
    if image_file:
        try:
            content = await image_file.read()
            image_b64 = base64.b64encode(content).decode("utf-8")
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid image file")

    # 3. AI Service í˜¸ì¶œ
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    
    search_strategy = "SMART_HYBRID"
    search_path = "INTERNAL"
    ai_summary = "ê²€ìƒ‰ ê²°ê³¼ìž…ë‹ˆë‹¤."
    ref_image_url = None
    candidates = []
    
    bert_vec: Optional[List[float]] = None
    clip_vec: Optional[List[float]] = None
    
    # âœ… í•­ìƒ determine-path í˜¸ì¶œ
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                # ê²½ë¡œ ê²°ì • API í˜¸ì¶œ
                path_res = await client.post(
                    f"{AI_SERVICE_API_URL}/determine-path",
                    json={"query": query}
                )
                search_path = "INTERNAL"
                if path_res.status_code == 200:
                    search_path = path_res.json().get("path", "INTERNAL")
                
                logger.info(f"ðŸ›¤ï¸ Search Path Decision: {search_path}")
                
                # ê²½ë¡œì— ë”°ë¼ ì ì ˆí•œ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
                endpoint = "/process-external" if search_path == 'EXTERNAL' else "/process-internal"
                payload = {"query": query, "image_b64": image_b64}
                
                ai_res = await client.post(f"{AI_SERVICE_API_URL}{endpoint}", json=payload)
                ai_res.raise_for_status()
                
                data = ai_res.json()
                
                # ë²¡í„° ì¶”ì¶œ
                if "vectors" in data:
                    bert_vec = data["vectors"].get("bert")
                    clip_vec = data["vectors"].get("clip")
                    logger.info(f"ðŸ“Š Vectors received - BERT: {len(bert_vec) if bert_vec else 0}dim, CLIP: {len(clip_vec) if clip_vec else 0}dim")
                elif "vector" in data:
                    bert_vec = data["vector"]
                
                # AI ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                if "ai_analysis" in data and data["ai_analysis"]:
                    analysis = data["ai_analysis"]
                    ai_summary = analysis.get("summary") or ai_summary
                    ref_image_url = analysis.get("reference_image")
                    candidates = analysis.get("candidates", [])
                else:
                    ai_summary = data.get("description") or data.get("reason") or ai_summary
                    ref_image_url = data.get("ref_image")
                
                search_strategy = data.get("strategy", search_path).upper()
                
                # ì™¸ë¶€ ì´ë¯¸ì§€ URLì´ë©´ í”„ë¡ì‹œ ì²˜ë¦¬
                if ref_image_url and ref_image_url.startswith("http"):
                    logger.info(f"ðŸ”„ Proxying reference image...")
                    proxy_image = await fetch_image_as_base64(ref_image_url)
                    if proxy_image:
                        ref_image_url = proxy_image
                
                break  # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ

        except Exception as e:
            logger.warning(f"âš ï¸ AI Service Retry ({attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                search_strategy = "KEYWORD_FALLBACK"
                logger.error(f"âŒ AI Service failed after {max_retries} retries")
            await asyncio.sleep(1)

    # 4. ðŸŒŸ ê²€ìƒ‰ ì‹¤í–‰ - ê²½ë¡œì— ë”°ë¼ ë‹¤ë¥¸ ì „ëžµ
    results = []
    
    try:
        # âœ… í•µì‹¬ ìˆ˜ì •: EXTERNAL ê²½ë¡œ (ì—°ì˜ˆì¸ íŒ¨ì…˜ ë“±) â†’ CLIP ì´ë¯¸ì§€ ë²¡í„°ë¡œ ê²€ìƒ‰
        if search_path == "EXTERNAL" and clip_vec and len(clip_vec) == 512:
            logger.info(f"ðŸ–¼ï¸ Using CLIP image vector search (512-dim)")
            
            # CLIP ì´ë¯¸ì§€ ë²¡í„°ë¡œ ì‹œê°ì  ìœ ì‚¬ë„ ê²€ìƒ‰
            results = await crud_product.search_by_clip_vector(
                db,
                clip_vector=clip_vec,
                limit=limit,
                filter_gender=target_gender
            )
            
            if results:
                search_strategy = "CLIP_VISUAL_SEARCH"
                logger.info(f"âœ… CLIP search found {len(results)} products")
            else:
                # CLIP ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ BERTë¡œ Fallback
                logger.info(f"âš ï¸ CLIP search empty, falling back to BERT")
                if bert_vec and len(bert_vec) == 768:
                    results = await crud_product.search_hybrid(
                        db,
                        bert_vector=bert_vec,
                        limit=limit,
                        filter_gender=target_gender
                    )
                    search_strategy = "BERT_FALLBACK"
        
        # INTERNAL ê²½ë¡œ ë˜ëŠ” CLIP ë²¡í„° ì—†ìŒ â†’ ê¸°ì¡´ ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ
        if not results:
            results = await crud_product.search_smart_hybrid(
                db,
                query=core_keyword,
                bert_vector=bert_vec,
                clip_vector=clip_vec,
                limit=limit,
                filter_gender=target_gender
            )
            
            # ê²°ê³¼ ì—†ìœ¼ë©´ ì „ì²´ ì¿¼ë¦¬ë¡œ ìž¬ì‹œë„
            if not results:
                results = await crud_product.search_smart_hybrid(
                    db,
                    query=query,
                    bert_vector=bert_vec,
                    clip_vector=clip_vec,
                    limit=limit,
                    filter_gender=None
                )
                if results:
                    search_strategy = "RELAXED_SEARCH"
        
        # ê·¸ëž˜ë„ ì—†ìœ¼ë©´ ìµœì‹  ìƒí’ˆ
        if not results:
            results = await crud_product.get_multi(db, limit=limit)
            search_strategy = "FALLBACK_LATEST"

    except Exception as e:
        logger.error(f"âŒ DB Search Error: {e}")
        raise HTTPException(status_code=500, detail="Database Search Failed")

    # 5. Response êµ¬ì„±
    product_responses = []
    for p in results:
        try:
            p_dict = {
                "id": p.id,
                "name": p.name or "Unnamed Product",
                "description": p.description or "",
                "price": float(p.price) if p.price else 0,
                "stock_quantity": int(p.stock_quantity) if p.stock_quantity else 0,
                "category": p.category or "Etc",
                "image_url": p.image_url or "",
                "gender": p.gender or "Unisex",
                "is_active": p.is_active if p.is_active is not None else True,
                "created_at": p.created_at,
                "updated_at": p.updated_at,
                "in_stock": (p.stock_quantity or 0) > 0
            }
            validated_product = ProductResponse.model_validate(p_dict)
            product_responses.append(validated_product)
        except ValidationError:
            continue

    logger.info(f"âœ… Search Complete: {len(product_responses)} products found (Strategy: {search_strategy})")

    return {
        "status": "SUCCESS",
        "search_path": search_strategy,
        "ai_analysis": {
            "summary": ai_summary,
            "reference_image": ref_image_url,
            "candidates": candidates
        },
        "products": product_responses
    }