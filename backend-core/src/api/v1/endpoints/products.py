import logging
import csv
import io
import shutil
import os
import uuid
from typing import Any, Dict, List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query, File, UploadFile
from sqlalchemy.ext.asyncio import AsyncSession
import httpx

# ì˜ì¡´ì„± ë° ëª¨ë“ˆ ì„í¬íŠ¸
from src.api import deps
from src.crud.crud_product import crud_product
from src.config.settings import settings
from src.schemas.user import UserResponse as User
from src.schemas.product import (
    ProductResponse, 
    ProductCreate, 
    CoordinationResponse, 
    LLMQueryBody
)

logger = logging.getLogger(__name__)
router = APIRouter()

# ------------------------------------------------------------------
# [Helper] ë¬¸ìì—´ ì •ë¦¬
# ------------------------------------------------------------------
def sanitize_string(value: Any) -> Any:
    if isinstance(value, str):
        return value.replace("\x00", "").strip()
    return value

# ------------------------------------------------------------------
# [Helper] Self-Healing
# ------------------------------------------------------------------
async def _heal_product_embedding(db: AsyncSession, product: Any) -> Any:
    """ìƒí’ˆ ë°ì´í„°(ì„ë² ë”©, ì„¤ëª…) ëˆ„ë½ ì‹œ AI ì„œë¹„ìŠ¤ë¡œ ë³µêµ¬"""
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    
    is_broken = (
        product.embedding is None or 
        (isinstance(product.embedding, list) and len(product.embedding) == 0) or
        product.description == "AI ë¶„ì„ ì‹¤íŒ¨" or 
        not product.description
    )
    
    if not is_broken:
        return product 

    logger.warning(f"ğŸš‘ [Self-Healing] Product ID {product.id} data missing. Attempting recovery...")

    new_description = product.description
    # 1. í…ìŠ¤íŠ¸ ìƒì„± ë³µêµ¬
    if not product.description or product.description == "AI ë¶„ì„ ì‹¤íŒ¨":
        try:
            async with httpx.AsyncClient(timeout=20.0) as client:
                prompt = f"ìƒí’ˆëª…: {product.name}, ì¹´í…Œê³ ë¦¬: {product.category}. ë§¤ë ¥ì ì¸ ì‡¼í•‘ëª° ìƒì„¸ ì„¤ëª…ì„ 5ë¬¸ì¥ ì‘ì„±í•´ì¤˜."
                res = await client.post(f"{AI_SERVICE_API_URL}/llm-generate-response", json={"prompt": prompt})
                if res.status_code == 200:
                    new_description = res.json().get("answer", product.name)
        except Exception as e:
            logger.error(f"Heal Description Failed: {e}")

    # 2. ì„ë² ë”© ë³µêµ¬
    new_vector = product.embedding
    try:
        text_to_embed = f"{product.name} {product.category} {new_description}"
        async with httpx.AsyncClient(timeout=10.0) as client:
            res = await client.post(f"{AI_SERVICE_API_URL}/embed-text", json={"text": text_to_embed})
            if res.status_code == 200:
                new_vector = res.json().get("vector", [])
    except Exception as e:
        logger.error(f"Heal Embedding Failed: {e}")

    # 3. DB ì—…ë°ì´íŠ¸
    if new_vector and len(new_vector) > 0:
        update_data = {"embedding": new_vector}
        if new_description != product.description:
            update_data["description"] = new_description
            
        product = await crud_product.update(db, db_obj=product, obj_in=update_data)
        logger.info(f"âœ… Product {product.id} healed.")
    
    return product


# =========================================================
# 1ï¸âƒ£ [API] ì´ë¯¸ì§€ ìë™ ë¶„ì„ ì—…ë¡œë“œ (ë‹¨ì¼) - ê²½ë¡œ ìˆ˜ì •ë¨! ğŸš¨
# =========================================================
@router.post("/upload/image-auto", response_model=ProductResponse)
async def upload_product_image_auto(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
):
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    ai_analyzed_data = {}
    
    logger.info(f"Processing Image: {file.filename}")

    # [Step A] AI ì„œë¹„ìŠ¤ë¡œ ì´ë¯¸ì§€ ì „ì†¡
    async with httpx.AsyncClient(timeout=60.0) as client:
        try:
            await file.seek(0)
            file_content = await file.read()
            files = {"file": (file.filename, file_content, file.content_type)}
            
            response = await client.post(
                f"{AI_SERVICE_API_URL}/analyze-image",
                files=files
            )
            
            if response.status_code == 200:
                ai_analyzed_data = response.json()
            else:
                logger.error(f"AI Service Error ({response.status_code}): {response.text}")
        except Exception as e:
            logger.error(f"AI Connection Error: {e}")

    # [Step B] ë¡œì»¬ ì €ì¥ (ê²½ë¡œ ìˆ˜ì •ë¨)
    try:
        # âœ… [FIX] ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (main.py, upload.pyì™€ ì¼ì¹˜ì‹œí‚´)
        UPLOAD_DIR = "/app/src/static/images"
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        
        file_ext = os.path.splitext(file.filename)[1]
        unique_filename = f"{uuid.uuid4()}{file_ext}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)
        
        with open(file_path, "wb") as buffer:
            buffer.write(file_content)
            
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ http://localhost:8000 ì„ ë¶™ì—¬ì£¼ë¯€ë¡œ ê²½ë¡œëŠ” /static/... ìœ¼ë¡œ ì €ì¥
        final_image_url = f"/static/images/{unique_filename}"
        
    except Exception as e:
        logger.error(f"File Save Error: {e}")
        raise HTTPException(status_code=500, detail="ì„œë²„ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

    # [Step C] ë°ì´í„° íŒŒì‹±
    raw_name = ai_analyzed_data.get("name")
    if not raw_name or len(str(raw_name).strip()) < 2:
        final_name = f"ìƒí’ˆ {file.filename}"
    else:
        final_name = str(raw_name).strip()

    raw_desc = ai_analyzed_data.get("description")
    final_desc = str(raw_desc).strip() if raw_desc else "AI ë¶„ì„ ì¤‘... ìƒì„¸ ë‚´ìš©ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”."

    final_gender = ai_analyzed_data.get("gender", "Unisex")

    try:
        final_price = int(ai_analyzed_data.get("price", 0))
    except:
        final_price = 0

    # BERT ë²¡í„° (768ì°¨ì›)
    vector = ai_analyzed_data.get("vector", [])
    if not vector:
        logger.warning("âš ï¸ Empty BERT vector received from AI.")

    # CLIP ë²¡í„° (512ì°¨ì›)
    vector_clip = ai_analyzed_data.get("vector_clip", [])
    if not vector_clip:
        logger.warning("âš ï¸ Empty CLIP vector received from AI. Image-based search will be limited.")

    logger.info(f"ğŸ“Š Vectors received - BERT: {len(vector)}dim, CLIP: {len(vector_clip)}dim")

    # [Step D] DB ì €ì¥
    product_in_data = {
        "name": sanitize_string(final_name),
        "category": sanitize_string(ai_analyzed_data.get("category", "Uncategorized")),
        "description": sanitize_string(final_desc),
        "price": final_price,
        "stock_quantity": 100,
        "image_url": final_image_url,
        "embedding": vector,              # BERT
        "embedding_clip": vector_clip,    # CLIP
        "gender": final_gender,
        "is_active": True
    }

    try:
        new_product = await crud_product.create(db, obj_in=product_in_data)
        new_product = await _heal_product_embedding(db, new_product)
        logger.info(f"âœ… Product created with ID {new_product.id} (BERT + CLIP vectors saved)")
        return new_product
    except Exception as e:
        logger.error(f"DB Insert Error: {e}")
        raise HTTPException(status_code=500, detail=f"DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")


# =========================================================
# 2ï¸âƒ£ [Mode 2] CSV ëŒ€ëŸ‰ ì—…ë¡œë“œ
# =========================================================
@router.post("/upload/csv")
async def upload_products_csv(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
):
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    content = await file.read()
    try:
        decoded_content = content.decode("utf-8")
    except UnicodeDecodeError:
        try:
            decoded_content = content.decode("cp949")
        except UnicodeDecodeError:
            decoded_content = content.decode("euc-kr", errors="ignore")

    csv_reader = csv.DictReader(io.StringIO(decoded_content))
    results = {"success": 0, "failed": 0, "errors": []}
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL

    for row in csv_reader:
        try:
            name = row.get("name") or row.get("ìƒí’ˆëª…")
            if not name: continue 

            category = row.get("category") or row.get("ì¹´í…Œê³ ë¦¬") or "Uncategorized"
            description = row.get("description") or row.get("ì„¤ëª…") or ""
            gender = row.get("gender") or row.get("ì„±ë³„") or "Unisex"
            
            price_raw = row.get("price") or row.get("ê°€ê²©") or "0"
            try:
                price = int(str(price_raw).replace(",", "").strip())
            except:
                price = 0

            stock_raw = row.get("stock_quantity") or row.get("ì¬ê³ ") or "100"
            try:
                stock = int(str(stock_raw).replace(",", "").strip())
            except:
                stock = 100
            
            image_url = row.get("image_url") or row.get("ì´ë¯¸ì§€") or "https://placehold.co/400x500?text=No+Image"

            # BERT ë²¡í„° ìƒì„±
            vector = []
            text_for_vector = f"[{gender}] {name} {category} {description}"
            
            async with httpx.AsyncClient(timeout=3.0) as client:
                try:
                    res = await client.post(
                        f"{AI_SERVICE_API_URL}/embed-text", 
                        json={"text": text_for_vector}
                    )
                    if res.status_code == 200:
                        vector = res.json().get("vector", [])
                except Exception:
                    pass 

            # CLIP ë²¡í„° ìƒì„±
            vector_clip = []
            if image_url and not image_url.startswith("https://placehold"):
                try:
                    async with httpx.AsyncClient(timeout=10.0) as client:
                        img_response = await client.get(image_url)
                        if img_response.status_code == 200:
                            import base64
                            image_b64 = base64.b64encode(img_response.content).decode("utf-8")
                            
                            clip_res = await client.post(
                                f"{AI_SERVICE_API_URL}/generate-clip-vector",
                                json={"image_b64": image_b64}
                            )
                            if clip_res.status_code == 200:
                                vector_clip = clip_res.json().get("vector", [])
                                logger.info(f"âœ… CLIP vector generated for {name}")
                except Exception as e:
                    logger.warning(f"âš ï¸ CLIP vector generation failed for {name}: {e}")

            product_in = {
                "name": sanitize_string(name),
                "category": sanitize_string(category),
                "description": sanitize_string(description),
                "price": price,
                "stock_quantity": stock,
                "image_url": image_url,
                "embedding": vector,              
                "embedding_clip": vector_clip,    
                "gender": gender,
                "is_active": True
            }
            
            await crud_product.create(db, obj_in=product_in)
            results["success"] += 1

        except Exception as e:
            results["failed"] += 1
            results["errors"].append(f"{name}: {str(e)}")

    return results


# =========================================================
# 3ï¸âƒ£ ì¼ë°˜ API (CRUD, Recommendation, LLM Query)
# =========================================================

@router.post("/", response_model=ProductResponse)
async def create_product(
    *,
    db: AsyncSession = Depends(deps.get_db),
    product_in: ProductCreate,
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """ë‹¨ì¼ ìƒí’ˆ ì§ì ‘ ìƒì„±"""
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    product_data = product_in.model_dump()
    for key, value in product_data.items():
        product_data[key] = sanitize_string(value)

    # BERT ì„ë² ë”© ìƒì„±
    embedding_vector = []
    text_to_embed = f"ìƒí’ˆëª…: {product_data['name']} | ì¹´í…Œê³ ë¦¬: {product_data.get('category', '')} | ì„¤ëª…: {product_data.get('description', '')}"
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{AI_SERVICE_API_URL}/embed-text",
                json={"text": text_to_embed}
            )
            if response.status_code == 200:
                embedding_vector = response.json().get("vector", [])
    except Exception as e:
        logger.error(f"âŒ Failed to generate BERT embedding: {e}")

    if embedding_vector:
        product_data["embedding"] = embedding_vector

    product = await crud_product.create(db, obj_in=product_data)
    return product

@router.get("/{product_id}", response_model=ProductResponse)
async def read_product(
    product_id: int,
    db: AsyncSession = Depends(deps.get_db),
) -> Any:
    product = await crud_product.get(db, product_id=product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    
    product = await _heal_product_embedding(db, product)
    return product

@router.post("/{product_id}/llm-query", response_model=Dict[str, str])
async def llm_query_product(
    product_id: int,
    query_body: LLMQueryBody,
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Dict[str, str]:
    product = await crud_product.get(db, product_id=product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    product = await _heal_product_embedding(db, product)

    context = (
        f"ìƒí’ˆëª…: {product.name}, ì¹´í…Œê³ ë¦¬: {product.category}, ê°€ê²©: {product.price}ì›, "
        f"ì„¤ëª…: {product.description}, ì„±ë³„: {product.gender}"
    )
    prompt = (
        f"ì‚¬ìš©ì ì§ˆë¬¸: {query_body.question}\n"
        f"ë‹¤ìŒ ìƒí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‡¼í•‘ëª° ì „ë¬¸ê°€ì²˜ëŸ¼ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\nì •ë³´: {context}"
    )
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL

    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            ai_response = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": prompt}
            )
            ai_response.raise_for_status()
            ai_data = ai_response.json()
            return {"answer": ai_data.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")}
        except Exception as e:
            logger.error(f"LLM Query failed: {e}")
            raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ í†µì‹  ì˜¤ë¥˜")

# --- AI Coordination ---
@router.get("/ai-coordination/{product_id}", response_model=CoordinationResponse)
async def get_ai_coordination_products(
    product_id: int, 
    db: AsyncSession = Depends(deps.get_db),
    current_user: Any = Depends(deps.get_current_user),
) -> CoordinationResponse:
    
    product = await crud_product.get(db, product_id=product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    product = await _heal_product_embedding(db, product)
    
    
    has_embedding = (
        product.embedding is not None and 
        hasattr(product.embedding, '__len__') and 
        len(product.embedding) > 0
    )
    
    if not has_embedding:
        raise HTTPException(status_code=503, detail="AI Service is currently unavailable to analyze this product.")
    
    coordination_prompt = (
        f"ìƒí’ˆëª… '{product.name}', ì„±ë³„ '{product.gender}', ì¹´í…Œê³ ë¦¬ '{product.category}'ì˜ ì½”ë””ì— ì í•©í•œ "
        f"ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬(ì˜ˆ: ìƒì˜ë©´ í•˜ì˜)ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œ 3ê°œë¥¼ í•œêµ­ì–´ë¡œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì¤˜."
    )
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    coordination_keywords = ["ì¶”ì²œ", "ë² ì´ì§", "ë°ì¼ë¦¬"]

    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": coordination_prompt}
            )
            if llm_res.status_code == 200:
                data = llm_res.json()
                answer_text = data.get("answer", "")
                extracted = [k.strip() for k in answer_text.split(',') if k.strip()]
                if extracted:
                    coordination_keywords = extracted
        except Exception as e:
            logger.error(f"LLM Keyword Generation failed: {e}")

    embedding_text = f"{product.name} ì½”ë”” {' '.join(coordination_keywords)}"
    coordination_vector = list(product.embedding) if product.embedding is not None else []
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            vector_res = await client.post(
                f"{AI_SERVICE_API_URL}/embed-text", 
                json={"text": embedding_text}
            )
            if vector_res.status_code == 200:
                coordination_vector = vector_res.json().get("vector", coordination_vector)
        except Exception as e:
            logger.error(f"Embedding API failed: {e}")

    coordination_products = await crud_product.search_by_vector(
        db, 
        query_vector=coordination_vector, 
        limit=5, 
        exclude_category=[product.category]
    )

    coordination_reason = (
        f"'{product.name}'ì™€(ê³¼) ì™„ë²½í•œ ë§¤ì¹˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ì•„ì´í…œë“¤ì…ë‹ˆë‹¤.\n"
        f"AI ì¶”ì²œ í‚¤ì›Œë“œ: #{', #'.join(coordination_keywords[:3])}"
    )

    return CoordinationResponse(
        answer=coordination_reason,
        products=[ProductResponse.model_validate(p) for p in coordination_products]
    )

# --- Related Recommendations ---

@router.get("/related-price/{product_id}", response_model=CoordinationResponse)
async def get_related_by_price(
    product_id: int, 
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    product = await _heal_product_embedding(db, product) 
    
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="AI Analysis Required")
    
    price_range = product.price * 0.15
    min_p = max(0, int(product.price - price_range))
    max_p = int(product.price + price_range)

    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=product.embedding,
        limit=5,
        min_price=min_p,
        max_price=max_p,
        exclude_id=[product.id]
    )

    reason = (
        f"ê°€ê²©ëŒ€({min_p:,}ì› ~ {max_p:,}ì›)ê°€ ë¹„ìŠ·í•œ ìƒí’ˆ ì¤‘ì—ì„œ, "
        f"'{product.name}'ì™€ ìŠ¤íƒ€ì¼ì´ ê°€ì¥ ìœ ì‚¬í•œ ìƒí’ˆë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    )

    return CoordinationResponse(
        answer=reason,
        products=[ProductResponse.model_validate(p) for p in related_products]
    )

@router.get("/related-color/{product_id}", response_model=CoordinationResponse)
async def get_related_by_color(
    product_id: int, 
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    product = await _heal_product_embedding(db, product)
    
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="AI Analysis Required")
    
    color_prompt = f"ìƒí’ˆ '{product.name}'ì˜ ì„¤ëª…ì—ì„œ ê°€ì¥ ì§€ë°°ì ì¸ ìƒ‰ìƒ í‚¤ì›Œë“œ 1ê°œë§Œ (ì˜ˆ: ë¸”ë™, ë„¤ì´ë¹„) ë‹µë³€í•˜ì‹œì˜¤."
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    target_color = "ìœ ì‚¬ìƒ‰ìƒ"
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": color_prompt}
            )
            if llm_res.status_code == 200:
                target_color = llm_res.json().get("answer", "ìœ ì‚¬ìƒ‰ìƒ")
        except Exception:
            pass

    embedding_text = f"{product.name} ë””ìì¸ {target_color} ìƒ‰ìƒ"
    color_vector = product.embedding 
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        try:
            vector_res = await client.post(
                f"{AI_SERVICE_API_URL}/embed-text", 
                json={"text": embedding_text}
            )
            if vector_res.status_code == 200:
                color_vector = vector_res.json().get("vector", [])
        except Exception:
            pass
    
    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=color_vector,
        limit=5,
        exclude_id=[product.id]
    )
    
    return CoordinationResponse(
        answer=f"'{product.name}'ì˜ ë””ìì¸ì€ ìœ ì§€í•˜ë©´ì„œ, '{target_color}' ê³„ì—´ì˜ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
        products=[ProductResponse.model_validate(p) for p in related_products]
    )

@router.get("/related-brand/{product_id}", response_model=CoordinationResponse)
async def get_related_by_brand(
    product_id: int, 
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    product = await _heal_product_embedding(db, product)
    
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="AI Analysis Required")
    
    style_prompt = f"'{product.name}' ìƒí’ˆì˜ ìŠ¤íƒ€ì¼(ì˜ˆ: ë¯¸ë‹ˆë©€ë¦¬ì¦˜, ìŠ¤íŠ¸ë¦¬íŠ¸) í‚¤ì›Œë“œ 3ê°œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•˜ì‹œì˜¤."
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL
    style_keywords = ["ìœ ì‚¬ ìŠ¤íƒ€ì¼"]
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": style_prompt}
            )
            if llm_res.status_code == 200:
                text = llm_res.json().get("answer", "")
                style_keywords = [k.strip() for k in text.split(',') if k.strip()]
        except Exception:
            pass

    embedding_text = f"ë‹¤ë¥¸ ë¸Œëœë“œ {product.category} {', '.join(style_keywords)}"
    brand_vector = product.embedding 
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        try:
            vector_res = await client.post(
                f"{AI_SERVICE_API_URL}/embed-text", 
                json={"text": embedding_text}
            )
            if vector_res.status_code == 200:
                brand_vector = vector_res.json().get("vector", [])
        except Exception:
            pass
        
    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=brand_vector,
        limit=5,
        exclude_id=[product.id] 
    )

    return CoordinationResponse(
        answer=f"'{product.name}'ì™€ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼({', '.join(style_keywords)})ì´ì§€ë§Œ, ë‹¤ë¥¸ ë¸Œëœë“œì˜ ìœ ì‚¬ ìƒí’ˆë“¤ì„ ì—„ì„ í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤.",
        products=[ProductResponse.model_validate(p) for p in related_products]
    )